import SwiftUI
import CoreData

struct RecordingView: View {
    @Environment(\.managedObjectContext) private var viewContext
    @Environment(\.dismiss) private var dismiss
    @StateObject private var audioRecorder = AudioRecorderManager()
    @State private var sessionTitle = ""
    @State private var showingPermissionAlert = false
    @State private var showingAnalysisView = false
    @State private var completedSession: AudioSession?
    @State private var showingFilePicker = false
    @State private var selectedFileURL: URL?
    @State private var fileInfo: AudioFileInfo?
    
    var body: some View {
        NavigationView {
            VStack(spacing: 30) {
                // ã‚¿ã‚¤ãƒˆãƒ«å…¥åŠ›
                VStack(alignment: .leading, spacing: 8) {
                    Text("éŒ²éŸ³ã‚¿ã‚¤ãƒˆãƒ«")
                        .font(.headline)
                    TextField("éŒ²éŸ³ã‚»ãƒƒã‚·ãƒ§ãƒ³åã‚’å…¥åŠ›ï¼ˆä»»æ„ï¼‰", text: $sessionTitle)
                        .textFieldStyle(RoundedBorderTextFieldStyle())
                }
                .padding(.horizontal)
                
                Spacer()
                
                // éŒ²éŸ³çŠ¶æ…‹è¡¨ç¤º
                VStack(spacing: 20) {
                    // éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼
                    AudioLevelVisualizer(level: audioRecorder.audioLevels, isRecording: audioRecorder.isRecording)
                    
                    // æ™‚é–“è¡¨ç¤º
                    VStack(spacing: 8) {
                        Text(audioRecorder.formatTime(audioRecorder.recordingDuration))
                            .font(.system(size: 48, weight: .thin, design: .monospaced))
                            .foregroundColor(audioRecorder.isRecording ? .red : .primary)
                        
                        if audioRecorder.isRecording {
                            Text("æ®‹ã‚Š \(audioRecorder.formatTime(audioRecorder.remainingTime))")
                                .font(.caption)
                                .foregroundColor(.gray)
                        }
                    }
                    
                    // éŒ²éŸ³çŠ¶æ…‹ãƒ†ã‚­ã‚¹ãƒˆ
                    Text(audioRecorder.isRecording ? "éŒ²éŸ³ä¸­..." : "éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹æº–å‚™ãŒã§ãã¾ã—ãŸ")
                        .font(.subheadline)
                        .foregroundColor(.gray)
                }
                
                Spacer()
                
                // ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³
                VStack(spacing: 20) {
                    // ãƒ¡ã‚¤ãƒ³éŒ²éŸ³ãƒœã‚¿ãƒ³
                    Button(action: {
                        if audioRecorder.hasPermission {
                            if audioRecorder.isRecording {
                                audioRecorder.stopRecording()
                                // ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§ç¢ºå®Ÿã«å®Ÿè¡Œ
                                DispatchQueue.main.async {
                                    saveRecordingSession()
                                }
                            } else {
                                audioRecorder.startRecording()
                            }
                        } else {
                            showingPermissionAlert = true
                        }
                    }) {
                        Image(systemName: audioRecorder.isRecording ? "stop.circle.fill" : "record.circle.fill")
                            .font(.system(size: 80))
                            .foregroundColor(audioRecorder.isRecording ? .red : .blue)
                    }
                    .disabled(!audioRecorder.hasPermission)
                    
                    // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ï¼ˆéŒ²éŸ³ä¸­ã®ã¿è¡¨ç¤ºï¼‰
                    if audioRecorder.isRecording {
                        Button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«") {
                            audioRecorder.cancelRecording()
                        }
                        .foregroundColor(.red)
                    }
                }
                
                Spacer()
            }
            .navigationTitle("éŒ²éŸ³")
            .navigationBarTitleDisplayMode(.inline)
            .toolbar {
                ToolbarItem(placement: .navigationBarLeading) {
                    Button("é–‰ã˜ã‚‹") {
                        if audioRecorder.isRecording {
                            audioRecorder.cancelRecording()
                        }
                        dismiss()
                    }
                    .disabled(audioRecorder.isRecording)
                }
                
                ToolbarItem(placement: .navigationBarTrailing) {
                    Button("ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ") {
                        showingFilePicker = true
                    }
                    .disabled(audioRecorder.isRecording)
                }
            }
        }
        .alert("ãƒã‚¤ã‚¯ã®è¨±å¯ãŒå¿…è¦ã§ã™", isPresented: $showingPermissionAlert) {
            Button("è¨­å®šã‚’é–‹ã") {
                if let settingsUrl = URL(string: UIApplication.openSettingsURLString) {
                    UIApplication.shared.open(settingsUrl)
                }
            }
            Button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", role: .cancel) { }
        } message: {
            Text("éŒ²éŸ³æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€è¨­å®šã‚¢ãƒ—ãƒªã§ãƒã‚¤ã‚¯ã®ä½¿ç”¨ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚")
        }
        .alert("ã‚¨ãƒ©ãƒ¼", isPresented: .constant(audioRecorder.errorMessage != nil)) {
            Button("OK") {
                audioRecorder.errorMessage = nil
            }
        } message: {
            Text(audioRecorder.errorMessage ?? "")
        }
        .fullScreenCover(isPresented: $showingAnalysisView) {
            if let session = completedSession {
                AnalysisProcessingView(audioSession: session)
                    .onAppear {
                        print("ğŸ“Š AnalysisProcessingViewã‚·ãƒ¼ãƒˆè¡¨ç¤ºé–‹å§‹")
                    }
            } else {
                VStack {
                    Text("ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    Button("é–‰ã˜ã‚‹") {
                        showingAnalysisView = false
                    }
                }
                .onAppear {
                    print("âŒ completedSessionãŒnil")
                }
            }
        }
        .onChange(of: showingAnalysisView) { isShowing in
            print("ğŸ“Š showingAnalysisViewå¤‰æ›´: \(isShowing)")
            print("ğŸ“Š completedSession: \(completedSession?.id?.uuidString ?? "nil")")
        }
        .onAppear {
            audioRecorder.checkPermissions()
        }
        .sheet(isPresented: $showingFilePicker) {
            FilePickerView(
                selectedURL: $selectedFileURL,
                allowedTypes: [.audio, .mpeg4Audio, .wav, .mp3],
                onPick: { url in
                    print("ğŸµ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠå®Œäº†: \(url)")
                    print("- ãƒ•ã‚¡ã‚¤ãƒ«å: \(url.lastPathComponent)")
                    print("- ãƒ‘ã‚¹: \(url.path)")
                    print("- å­˜åœ¨ç¢ºèª: \(FileManager.default.fileExists(atPath: url.path))")
                    validateAndProcessFile(url)
                },
                onCancel: {
                    print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã‚­ãƒ£ãƒ³ã‚»ãƒ«")
                    showingFilePicker = false
                }
            )
        }
        .sheet(item: $fileInfo) { info in
            FileInfoView(
                fileInfo: info,
                onConfirm: {
                    print("ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªå®Œäº†: åˆ†æå‡¦ç†é–‹å§‹")
                    fileInfo = nil
                    processAudioFile(info)
                },
                onCancel: {
                    print("ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªã‚­ãƒ£ãƒ³ã‚»ãƒ«")
                    fileInfo = nil
                }
            )
            .presentationDetents([.medium, .large])
            .presentationDragIndicator(.visible)
            .onAppear {
                print("ğŸ“‹ FileInfoViewã‚·ãƒ¼ãƒˆè¡¨ç¤ºé–‹å§‹")
            }
        }
    }
    
    private func saveRecordingSession() {
        guard let recordingURL = audioRecorder.recordingURL else {
            audioRecorder.errorMessage = "éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            return
        }
        
        let session = AudioSession(context: viewContext, 
                                   title: sessionTitle.isEmpty ? "éŒ²éŸ³ã‚»ãƒƒã‚·ãƒ§ãƒ³" : sessionTitle,
                                   duration: audioRecorder.recordingDuration)
        session.filePath = recordingURL.path
        
        // å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        print("AudioSession Debug Info:")
        print("- ID: \(session.id?.uuidString ?? "nil")")
        print("- Title: \(session.title ?? "nil")")
        print("- Duration: \(session.duration)")
        print("- FilePath: \(session.filePath ?? "nil")")
        print("- CreatedAt: \(session.createdAt?.description ?? "nil")")
        
        do {
            try viewContext.save()
            completedSession = session
            showingAnalysisView = true
        } catch {
            // Core Dataã®validationã‚¨ãƒ©ãƒ¼ã‚’è©³ã—ãèª¿æŸ»
            let nsError = error as NSError
            var errorMessages: [String] = ["éŒ²éŸ³ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"]
            
            // ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã¨è©³ç´°ã‚’å‡ºåŠ›
            errorMessages.append("Error Code: \(nsError.code)")
            errorMessages.append("Error Domain: \(nsError.domain)")
            
            // validation errorsã®è©³ç´°ã‚’å–å¾—
            if let validationErrors = nsError.userInfo[NSDetailedErrorsKey] as? [NSError] {
                errorMessages.append("Validation Errors:")
                for (index, validationError) in validationErrors.enumerated() {
                    errorMessages.append("\(index + 1). \(validationError.localizedDescription)")
                    if let key = validationError.userInfo[NSValidationKeyErrorKey] as? String {
                        errorMessages.append("   Key: \(key)")
                    }
                    if let value = validationError.userInfo[NSValidationValueErrorKey] {
                        errorMessages.append("   Value: \(value)")
                    }
                }
            }
            
            // ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
            print("Core Data Save Error Details:")
            errorMessages.forEach { print($0) }
            
            audioRecorder.errorMessage = errorMessages.joined(separator: "\n")
        }
    }
    
    private func validateAndProcessFile(_ url: URL) {
        showingFilePicker = false
        
        print("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼é–‹å§‹...")
        
        Task {
            let result = await AudioFileValidator.shared.validateAudioFile(at: url)
            
            await MainActor.run {
                switch result {
                case .success(let info):
                    print("âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼æˆåŠŸ - FileInfoViewè¡¨ç¤ºæº–å‚™")
                    print("- Infoè©³ç´°: \(info.url.lastPathComponent), \(info.formattedDuration), \(info.formattedFileSize)")
                    
                    // fileInfoã‚’è¨­å®šï¼ˆã‚·ãƒ¼ãƒˆã¯è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
                    self.fileInfo = info
                    print("ğŸ“‹ fileInfoè¨­å®šå®Œäº†: \(self.fileInfo?.id.uuidString ?? "nil")")
                    
                case .failure(let error):
                    print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å¤±æ•—: \(error)")
                    audioRecorder.errorMessage = error
                }
            }
        }
    }
    
    private func processAudioFile(_ info: AudioFileInfo) {
        
        print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹:")
        print("- å…ƒãƒ•ã‚¡ã‚¤ãƒ«URL: \(info.url)")
        print("- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(info.formattedFileSize)")
        print("- å†ç”Ÿæ™‚é–“: \(info.formattedDuration)")
        
        // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ãƒ¼ãƒ—ã‚¢ã‚¯ã‚»ã‚¹é–‹å§‹
        let accessSucceeded = info.url.startAccessingSecurityScopedResource()
        print("- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ãƒ¼ãƒ—ã‚¢ã‚¯ã‚»ã‚¹: \(accessSucceeded ? "æˆåŠŸ" : "å¤±æ•—")")
        
        defer {
            if accessSucceeded {
                info.url.stopAccessingSecurityScopedResource()
            }
        }
        
        // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
        guard let copiedURL = AudioFileValidator.shared.copyToDocuments(from: info.url) else {
            audioRecorder.errorMessage = "ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ"
            return
        }
        
        print("- ã‚³ãƒ”ãƒ¼å…ˆURL: \(copiedURL)")
        
        // AudioSessionã‚’ä½œæˆ
        let fileName = info.url.deletingPathExtension().lastPathComponent
        let session = AudioSession(context: viewContext,
                                   title: sessionTitle.isEmpty ? fileName : sessionTitle,
                                   duration: info.duration)
        session.filePath = copiedURL.path
        
        // å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
        print("AudioSessionä½œæˆ:")
        print("- ID: \(session.id?.uuidString ?? "nil")")
        print("- Title: \(session.title ?? "nil")")
        print("- Duration: \(session.duration)")
        print("- FilePath: \(session.filePath ?? "nil")")
        print("- CreatedAt: \(session.createdAt?.description ?? "nil")")
        
        do {
            try viewContext.save()
            print("âœ… AudioSessionä¿å­˜æˆåŠŸ")
            
            // ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§ç¢ºå®Ÿã«çŠ¶æ…‹ã‚’æ›´æ–°
            DispatchQueue.main.async {
                print("ğŸ“Š çŠ¶æ…‹æ›´æ–°é–‹å§‹")
                self.completedSession = session
                print("ğŸ“Š completedSessionè¨­å®š: \(session.id?.uuidString ?? "nil")")
                self.showingAnalysisView = true
                print("ğŸ“Š showingAnalysisViewè¨­å®š: \(self.showingAnalysisView)")
                print("ğŸ“Š åˆ†æç”»é¢è¡¨ç¤ºé–‹å§‹")
            }
            
        } catch {
            let nsError = error as NSError
            print("âŒ AudioSessionä¿å­˜ã‚¨ãƒ©ãƒ¼:")
            print("- Error Code: \(nsError.code)")
            print("- Error Domain: \(nsError.domain)")
            print("- Description: \(nsError.localizedDescription)")
            
            // è©³ç´°ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®è¡¨ç¤º
            if let validationErrors = nsError.userInfo[NSDetailedErrorsKey] as? [NSError] {
                for (index, validationError) in validationErrors.enumerated() {
                    print("  \(index + 1). \(validationError.localizedDescription)")
                    if let key = validationError.userInfo[NSValidationKeyErrorKey] as? String {
                        print("     Key: \(key)")
                    }
                }
            }
            
            audioRecorder.errorMessage = "ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        }
    }
}

struct AudioLevelVisualizer: View {
    let level: Float
    let isRecording: Bool
    
    var body: some View {
        ZStack {
            // èƒŒæ™¯å††
            Circle()
                .stroke(Color.gray.opacity(0.3), lineWidth: 4)
                .frame(width: 200, height: 200)
            
            // ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºå††
            Circle()
                .trim(from: 0, to: CGFloat(level))
                .stroke(
                    isRecording ? Color.red : Color.blue,
                    style: StrokeStyle(lineWidth: 8, lineCap: .round)
                )
                .frame(width: 200, height: 200)
                .rotationEffect(.degrees(-90))
                .animation(.easeInOut(duration: 0.1), value: level)
            
            // ä¸­å¤®ã‚¢ã‚¤ã‚³ãƒ³
            Image(systemName: isRecording ? "waveform" : "mic")
                .font(.system(size: 40))
                .foregroundColor(isRecording ? .red : .blue)
        }
    }
}

// åˆ†æå‡¦ç†ç”»é¢
struct AnalysisProcessingView: View {
    let audioSession: AudioSession
    @Environment(\.managedObjectContext) private var viewContext
    @Environment(\.dismiss) private var dismiss
    @StateObject private var analysisManager = AnalysisManager()
    @State private var showingResults = false
    
    var body: some View {
        NavigationView {
            VStack(spacing: 30) {
                Spacer()
                
                // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
                VStack(spacing: 20) {
                    ProgressView(value: analysisManager.analysisProgress)
                        .progressViewStyle(LinearProgressViewStyle())
                        .scaleEffect(x: 1, y: 2)
                    
                    Text(analysisManager.currentStep)
                        .font(.headline)
                    
                    Text("ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
                        .font(.caption)
                        .foregroundColor(.gray)
                }
                .padding()
                
                Spacer()
                
                if analysisManager.isAnalyzing {
                    Button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«") {
                        dismiss()
                    }
                    .foregroundColor(.red)
                } else {
                    Button("çµæœã‚’è¦‹ã‚‹") {
                        showingResults = true
                    }
                    .buttonStyle(.borderedProminent)
                }
            }
            .navigationTitle("åˆ†æä¸­")
            .navigationBarTitleDisplayMode(.inline)
        }
        .onAppear {
            print("ğŸ“Š AnalysisProcessingViewè¡¨ç¤ºå®Œäº†")
            print("- AudioSession ID: \(audioSession.id?.uuidString ?? "nil")")
            print("- APIã‚­ãƒ¼å­˜åœ¨ç¢ºèª: \(KeychainManager.shared.exists(for: .openAIAPIKey))")
            
            // APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å®Ÿéš›ã®åˆ†æã€ãªã‘ã‚Œã°ãƒ¢ãƒƒã‚¯åˆ†æ
            if KeychainManager.shared.exists(for: .openAIAPIKey) {
                print("ğŸ”‘ å®Ÿéš›ã®åˆ†æå‡¦ç†é–‹å§‹")
                analysisManager.analyzeAudioSession(audioSession, context: viewContext)
            } else {
                print("ğŸ­ ãƒ¢ãƒƒã‚¯åˆ†æå‡¦ç†é–‹å§‹")
                analysisManager.performMockAnalysis(for: audioSession, context: viewContext)
            }
        }
        .alert("ã‚¨ãƒ©ãƒ¼", isPresented: .constant(analysisManager.errorMessage != nil)) {
            Button("OK") {
                analysisManager.errorMessage = nil
                dismiss()
            }
        } message: {
            Text(analysisManager.errorMessage ?? "")
        }
        .onChange(of: analysisManager.isAnalyzing) {
            if !analysisManager.isAnalyzing && analysisManager.errorMessage == nil {
                // åˆ†æå®Œäº†å¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰è‡ªå‹•ã§çµæœç”»é¢ã«é·ç§»
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    showingResults = true
                }
            }
        }
        .sheet(isPresented: $showingResults) {
            if let analysis = audioSession.analysis {
                AnalysisResultView(analysis: analysis, onComplete: {
                    // çµæœç”»é¢ã‚’é–‰ã˜ã‚‹
                    showingResults = false
                    // åˆ†æå‡¦ç†ç”»é¢ã‚‚é–‰ã˜ã‚‹
                    DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                        dismiss()
                    }
                })
            }
        }
    }
}