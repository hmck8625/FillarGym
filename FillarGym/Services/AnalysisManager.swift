import Foundation
import CoreData
import Combine

class AnalysisManager: ObservableObject {
    @Published var isAnalyzing = false
    @Published var analysisProgress: Double = 0.0
    @Published var currentStep = ""
    @Published var errorMessage: String?
    
    private let openAIService = OpenAIService()
    private var cancellables = Set<AnyCancellable>()
    
    private let analysisSteps = [
        "éŸ³å£°ã‚’æº–å‚™ä¸­...",
        "éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...",
        "æ–‡å­—èµ·ã“ã—ä¸­...",
        "ãƒ•ã‚£ãƒ©ãƒ¼èªã‚’æ¤œå‡ºä¸­...",
        "åˆ†æçµæœã‚’ä¿å­˜ä¸­..."
    ]
    
    func analyzeAudioSession(_ audioSession: AudioSession, context: NSManagedObjectContext) {
        print("ğŸ¯ AnalysisManager.analyzeAudioSessioné–‹å§‹")
        print("- AudioSession ID: \(audioSession.id?.uuidString ?? "nil")")
        print("- FilePath: \(audioSession.filePath ?? "nil")")
        
        guard let filePath = audioSession.filePath else {
            print("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            errorMessage = "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            return
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰URLã‚’ä½œæˆï¼ˆfile://å½¢å¼ã®å ´åˆã¨ãƒ‘ã‚¹ã®ã¿ã®å ´åˆã«å¯¾å¿œï¼‰
        let audioURL: URL
        if filePath.hasPrefix("file://") {
            audioURL = URL(string: filePath)!
        } else {
            audioURL = URL(fileURLWithPath: filePath)
        }
        
        print("ğŸš€ åˆ†æå‡¦ç†çŠ¶æ…‹åˆæœŸåŒ–")
        isAnalyzing = true
        analysisProgress = 0.0
        updateStep(0)
        print("- isAnalyzing: \(isAnalyzing)")
        print("- analysisProgress: \(analysisProgress)")
        print("- currentStep: \(currentStep)")
        
        // Step 1: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            self.updateStep(1)
            
            // Step 2: Whisper APIã§æ–‡å­—èµ·ã“ã—
            self.openAIService.transcribeAudio(audioURL: audioURL)
                .receive(on: DispatchQueue.main)
                .sink(
                    receiveCompletion: { [weak self] completion in
                        if case .failure(let error) = completion {
                            self?.handleError(error)
                        }
                    },
                    receiveValue: { [weak self] transcription in
                        self?.updateStep(2)
                        self?.analyzeTranscription(transcription.text, for: audioSession, context: context)
                    }
                )
                .store(in: &self.cancellables)
        }
    }
    
    private func analyzeTranscription(_ text: String, for audioSession: AudioSession, context: NSManagedObjectContext) {
        updateStep(3)
        
        // æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜
        audioSession.transcription = text
        print("Transcription saved: \(text)")
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚’å–å¾—
        let request = NSFetchRequest<UserSettings>(entityName: "UserSettings")
        let userSettings = try? context.fetch(request).first
        let language = userSettings?.language ?? "ja"
        
        // GPT APIã§ãƒ•ã‚£ãƒ©ãƒ¼èªåˆ†æ
        openAIService.analyzeFillerWords(transcription: text, language: language, userSettings: userSettings)
            .receive(on: DispatchQueue.main)
            .sink(
                receiveCompletion: { [weak self] completion in
                    if case .failure(let error) = completion {
                        print("Analysis failed: \(error)")
                        self?.handleError(error)
                    }
                },
                receiveValue: { [weak self] analysisResponse in
                    print("Analysis completed: \(analysisResponse.total_filler_count) fillers detected")
                    self?.updateStep(4)
                    self?.saveAnalysisResults(analysisResponse, for: audioSession, context: context)
                }
            )
            .store(in: &cancellables)
    }
    
    private func saveAnalysisResults(_ response: FillerAnalysisResponse, for audioSession: AudioSession, context: NSManagedObjectContext) {
        print("ğŸ’¾ åˆ†æçµæœä¿å­˜é–‹å§‹:")
        print("- AudioSession ID: \(audioSession.id?.uuidString ?? "nil")")
        print("- AudioSession isDeleted: \(audioSession.isDeleted)")
        print("- AudioSession managedObjectContext: \(audioSession.managedObjectContext != nil)")
        print("- ãƒ•ã‚£ãƒ©ãƒ¼èªæ•°: \(response.total_filler_count)")
        
        // AudioSessionãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
        guard !audioSession.isDeleted, audioSession.managedObjectContext != nil else {
            print("âŒ AudioSessionãŒç„¡åŠ¹ã§ã™")
            handleError(NSError(domain: "AnalysisManager", code: 1, userInfo: [NSLocalizedDescriptionKey: "AudioSessionãŒç„¡åŠ¹ã§ã™"]))
            return
        }
        
        // æ—¢å­˜ã®åˆ†æãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¦å‰Šé™¤
        if let existingAnalysis = audioSession.analysis {
            print("âš ï¸ æ—¢å­˜ã®åˆ†æã‚’å‰Šé™¤: \(existingAnalysis.id?.uuidString ?? "nil")")
            context.delete(existingAnalysis)
        }
        
        // FillerAnalysisã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ä½œæˆ
        let analysis = FillerAnalysis(context: context, audioSession: audioSession)
        analysis.fillerCount = Int16(response.total_filler_count)
        analysis.fillerRate = response.filler_rate_per_minute
        analysis.speakingSpeed = response.speaking_speed
        
        // é–¢ä¿‚æ€§ã‚’æ˜ç¤ºçš„ã«è¨­å®š
        analysis.audioSession = audioSession
        audioSession.analysis = analysis
        
        // é–¢ä¿‚ã®ç¢ºèª
        print("- Analysis ID: \(analysis.id?.uuidString ?? "nil")")
        print("- Analysis AudioSession: \(analysis.audioSession?.id?.uuidString ?? "nil")")
        print("- Analysis Date: \(analysis.analysisDate?.description ?? "nil")")
        
        // æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚£ãƒ©ãƒ¼èªã‚’ä¿å­˜
        for (index, fillerWord) in response.filler_words.enumerated() {
            let fillerEntity = FillerWord(context: context)
            fillerEntity.id = UUID()
            fillerEntity.word = fillerWord.word
            fillerEntity.count = Int16(fillerWord.count)
            fillerEntity.confidence = fillerWord.confidence
            fillerEntity.timestamp = fillerWord.positions.first.map { Double($0) } ?? 0.0
            fillerEntity.analysis = analysis
            
            print("  - ãƒ•ã‚£ãƒ©ãƒ¼èª[\(index)]: \(fillerWord.word) (\(fillerWord.count)å›)")
        }
        
        // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å‰ã®æœ€çµ‚ç¢ºèª
        print("ä¿å­˜å‰ã®æ¤œè¨¼:")
        print("- Analysis has audioSession: \(analysis.audioSession != nil)")
        print("- AudioSession has valid ID: \(analysis.audioSession?.id != nil)")
        
        // Core Dataã«ä¿å­˜
        do {
            try context.save()
            print("âœ… åˆ†æçµæœä¿å­˜æˆåŠŸ")
            completeAnalysis()
        } catch {
            let nsError = error as NSError
            print("âŒ åˆ†æçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼:")
            print("- Error Code: \(nsError.code)")
            print("- Error Domain: \(nsError.domain)")
            print("- Description: \(nsError.localizedDescription)")
            
            // è©³ç´°ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®è¡¨ç¤º
            if let validationErrors = nsError.userInfo[NSDetailedErrorsKey] as? [NSError] {
                for (index, validationError) in validationErrors.enumerated() {
                    print("  \(index + 1). \(validationError.localizedDescription)")
                    if let key = validationError.userInfo[NSValidationKeyErrorKey] as? String {
                        print("     Key: \(key)")
                    }
                    if let value = validationError.userInfo[NSValidationValueErrorKey] {
                        print("     Value: \(value)")
                    }
                }
            }
            
            handleError(error)
        }
    }
    
    private func updateStep(_ stepIndex: Int) {
        if stepIndex < analysisSteps.count {
            currentStep = analysisSteps[stepIndex]
            analysisProgress = Double(stepIndex) / Double(analysisSteps.count)
        }
    }
    
    private func completeAnalysis() {
        analysisProgress = 1.0
        currentStep = "åˆ†æå®Œäº†"
        
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            self.isAnalyzing = false
            self.analysisProgress = 0.0
            self.currentStep = ""
        }
    }
    
    private func handleError(_ error: Error) {
        isAnalyzing = false
        analysisProgress = 0.0
        currentStep = ""
        errorMessage = error.localizedDescription
    }
    
    // MARK: - Mock Analysis (é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨)
    func performMockAnalysis(for audioSession: AudioSession, context: NSManagedObjectContext) {
        isAnalyzing = true
        analysisProgress = 0.0
        
        let mockSteps = analysisSteps
        var currentStepIndex = 0
        
        Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { timer in
            if currentStepIndex < mockSteps.count {
                self.currentStep = mockSteps[currentStepIndex]
                self.analysisProgress = Double(currentStepIndex + 1) / Double(mockSteps.count)
                currentStepIndex += 1
            } else {
                timer.invalidate()
                self.createMockAnalysisResults(for: audioSession, context: context)
            }
        }
    }
    
    private func createMockAnalysisResults(for audioSession: AudioSession, context: NSManagedObjectContext) {
        print("ğŸ­ ãƒ¢ãƒƒã‚¯åˆ†æçµæœä½œæˆé–‹å§‹:")
        print("- AudioSession ID: \(audioSession.id?.uuidString ?? "nil")")
        
        // æ—¢å­˜ã®åˆ†æãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¦å‰Šé™¤
        if let existingAnalysis = audioSession.analysis {
            print("âš ï¸ æ—¢å­˜ã®ãƒ¢ãƒƒã‚¯åˆ†æã‚’å‰Šé™¤: \(existingAnalysis.id?.uuidString ?? "nil")")
            context.delete(existingAnalysis)
        }
        
        // ãƒ¢ãƒƒã‚¯ç”¨ã®åˆ†æçµæœã‚’ä½œæˆ
        let analysis = FillerAnalysis(context: context, audioSession: audioSession)
        analysis.fillerCount = Int16.random(in: 3...15)
        analysis.fillerRate = Double.random(in: 2.0...8.0)
        analysis.speakingSpeed = Double.random(in: 120...180)
        
        // é–¢ä¿‚æ€§ã‚’æ˜ç¤ºçš„ã«è¨­å®š
        analysis.audioSession = audioSession
        audioSession.analysis = analysis
        
        print("- ãƒ¢ãƒƒã‚¯åˆ†æä½œæˆå®Œäº†: \(analysis.fillerCount)å€‹ã®ãƒ•ã‚£ãƒ©ãƒ¼èª")
        print("- Analysis AudioSession: \(analysis.audioSession?.id?.uuidString ?? "nil")")
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚’å–å¾—
        let request = NSFetchRequest<UserSettings>(entityName: "UserSettings")
        let userSettings = try? context.fetch(request).first
        let language = userSettings?.language ?? "ja"
        
        // ãƒ¢ãƒƒã‚¯ã®ãƒ•ã‚£ãƒ©ãƒ¼èªãƒ‡ãƒ¼ã‚¿ï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ©ãƒ¼èªã‚‚å«ã‚€ï¼‰
        var mockFillerWords = UserSettings.defaultFillerWords(for: language)
        if let customWords = userSettings?.customFillerWordsArray, !customWords.isEmpty {
            mockFillerWords.append(contentsOf: customWords)
        }
        
        // ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        let selectedWords = mockFillerWords.shuffled().prefix(Int.random(in: 2...4))
        
        for word in selectedWords {
            let fillerEntity = FillerWord(context: context)
            fillerEntity.id = UUID()
            fillerEntity.word = word
            fillerEntity.count = Int16.random(in: 1...5)
            fillerEntity.confidence = Double.random(in: 0.7...1.0)
            fillerEntity.timestamp = Double.random(in: 0...audioSession.duration)
            fillerEntity.analysis = analysis
        }
        
        // ãƒ¢ãƒƒã‚¯ã®æ–‡å­—èµ·ã“ã—ï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ©ãƒ¼èªã‚‚å«ã‚ã‚‹ï¼‰
        let fillerExamples = selectedWords.joined(separator: "ã€")
        audioSession.transcription = "ã“ã‚“ã«ã¡ã¯ã€\(fillerExamples)ã€ä»Šæ—¥ã¯ã§ã™ã­ã€ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚"
        
        do {
            try context.save()
            completeAnalysis()
        } catch {
            handleError(error)
        }
    }
}